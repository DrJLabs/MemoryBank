---
globs: ["**/*.py", "**/requirements.txt", "**/pyproject.toml", "**/setup.py", "**/Pipfile", "**/.python-version"]
alwaysApply: false
---
# Python Backend & AI Development Standards

## Python Configuration

### Project Structure
```
project/
├── api/                 # FastAPI routes
├── models/             # Database models
├── schemas/            # Pydantic schemas
├── services/           # Business logic
├── utils/              # Utility functions
├── memory/             # AI memory integration
├── vector_stores/      # Vector database handlers
├── embeddings/         # Embedding providers
└── tests/              # Test suites
```

### Modern Python Patterns (Python 3.10+)
```python
#!/usr/bin/env python3
"""
Enhanced Python module template with type safety and error handling
"""

import logging
from typing import Dict, List, Any, Optional, Union, Literal
from dataclasses import dataclass
from pathlib import Path
from datetime import datetime
import asyncio

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class Config:
    """Configuration with type hints and defaults"""
    api_url: str = "http://localhost:8765/api/v1"
    user_id: str = "drj"
    timeout: int = 30
    vector_db: Literal["chroma", "pinecone", "qdrant"] = "chroma"
```

## FastAPI Backend Patterns

### API Structure
```python
from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer
from pydantic import BaseModel, Field
from typing import List, Optional
import uvicorn

# App configuration
app = FastAPI(
    title="Memory-C* API",
    description="AI Memory Management System",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3010"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class MemoryRequest(BaseModel):
    content: str = Field(..., min_length=1, max_length=10000)
    category: str = Field(default="GENERAL")
    user_id: str = Field(..., min_length=1)
    metadata: Optional[Dict[str, Any]] = None

class MemoryResponse(BaseModel):
    id: str
    content: str
    category: str
    created_at: datetime
    confidence: Optional[float] = None

# Route patterns
@app.post("/api/v1/memories", response_model=MemoryResponse)
async def create_memory(
    request: MemoryRequest,
    current_user: str = Depends(get_current_user)
) -> MemoryResponse:
    """Create a new memory with proper validation"""
    try:
        memory = await memory_service.create_memory(request, current_user)
        return MemoryResponse(**memory.dict())
    except Exception as e:
        logger.error(f"Failed to create memory: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to create memory"
        )
```

### Database Integration (SQLAlchemy + Alembic)
```python
from sqlalchemy import Column, String, DateTime, Text, Float, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.dialects.postgresql import UUID
import uuid
from datetime import datetime

Base = declarative_base()

class Memory(Base):
    __tablename__ = "memories"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    content = Column(Text, nullable=False)
    category = Column(String(50), nullable=False, index=True)
    user_id = Column(String(100), nullable=False, index=True)
    embedding = Column(JSON)  # Store vector embeddings
    metadata = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def __repr__(self):
        return f"<Memory(id={self.id}, category={self.category})>"

# Repository pattern
class MemoryRepository:
    def __init__(self, db_session):
        self.db = db_session
    
    async def create_memory(self, memory_data: MemoryRequest) -> Memory:
        """Create memory with proper error handling"""
        try:
            memory = Memory(**memory_data.dict())
            self.db.add(memory)
            await self.db.commit()
            await self.db.refresh(memory)
            return memory
        except Exception as e:
            await self.db.rollback()
            logger.error(f"Database error creating memory: {e}")
            raise
```

## AI/Memory System Integration

### Vector Store Abstraction
```python
from abc import ABC, abstractmethod
from typing import List, Tuple, Any
import numpy as np

class VectorStore(ABC):
    """Abstract base class for vector stores"""
    
    @abstractmethod
    async def add_vectors(
        self, 
        vectors: List[List[float]], 
        metadatas: List[Dict[str, Any]]
    ) -> List[str]:
        """Add vectors with metadata"""
        pass
    
    @abstractmethod
    async def search_similar(
        self, 
        query_vector: List[float], 
        top_k: int = 5
    ) -> List[Tuple[str, float]]:
        """Search for similar vectors"""
        pass

class ChromaVectorStore(VectorStore):
    """ChromaDB implementation"""
    
    def __init__(self, collection_name: str = "memories"):
        import chromadb
        self.client = chromadb.Client()
        self.collection = self.client.get_or_create_collection(collection_name)
    
    async def add_vectors(
        self, 
        vectors: List[List[float]], 
        metadatas: List[Dict[str, Any]]
    ) -> List[str]:
        ids = [str(uuid.uuid4()) for _ in vectors]
        self.collection.add(
            embeddings=vectors,
            metadatas=metadatas,
            ids=ids
        )
        return ids
```

### Embedding Service
```python
from openai import AsyncOpenAI
from typing import List, Union
import asyncio

class EmbeddingService:
    """Service for generating embeddings"""
    
    def __init__(self, model: str = "text-embedding-3-small"):
        self.client = AsyncOpenAI()
        self.model = model
        
    async def embed_text(self, text: str) -> List[float]:
        """Generate embedding for single text"""
        try:
            response = await self.client.embeddings.create(
                input=text,
                model=self.model
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embedding generation failed: {e}")
            raise
    
    async def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple texts"""
        tasks = [self.embed_text(text) for text in texts]
        return await asyncio.gather(*tasks)
```

### Memory Search Service
```python
class MemorySearchService:
    """Intelligent memory search with multiple strategies"""
    
    def __init__(
        self, 
        vector_store: VectorStore,
        embedding_service: EmbeddingService,
        memory_repo: MemoryRepository
    ):
        self.vector_store = vector_store
        self.embedding_service = embedding_service
        self.memory_repo = memory_repo
    
    async def intelligent_search(
        self, 
        query: str, 
        query_type: str = "general",
        limit: int = 5
    ) -> Dict[str, Any]:
        """Multi-strategy search with confidence scoring"""
        
        # Generate query embedding
        query_embedding = await self.embedding_service.embed_text(query)
        
        # Vector similarity search
        similar_memories = await self.vector_store.search_similar(
            query_embedding, 
            top_k=limit * 2  # Get more for filtering
        )
        
        # Confidence scoring logic
        results = []
        for memory_id, similarity in similar_memories:
            memory = await self.memory_repo.get_by_id(memory_id)
            if memory:
                confidence = self._calculate_confidence(
                    similarity, memory, query_type
                )
                if confidence > 0.3:  # Confidence threshold
                    results.append({
                        "memory": memory,
                        "confidence": confidence,
                        "similarity": similarity
                    })
        
        # Sort by confidence and limit results
        results.sort(key=lambda x: x["confidence"], reverse=True)
        
        return {
            "query": query,
            "results": results[:limit],
            "total_found": len(results),
            "search_strategies": ["vector_similarity", "confidence_scoring"]
        }
    
    def _calculate_confidence(
        self, 
        similarity: float, 
        memory: Memory, 
        query_type: str
    ) -> float:
        """Calculate confidence score"""
        base_confidence = similarity
        
        # Category boost
        if memory.category.lower() == query_type.lower():
            base_confidence += 0.1
        
        # Recency boost (newer memories get slight boost)
        days_old = (datetime.utcnow() - memory.created_at).days
        recency_boost = max(0, 0.05 - (days_old * 0.001))
        
        return min(1.0, base_confidence + recency_boost)
```

## Error Handling & Resilience

### Custom Exception Classes
```python
class MemorySystemError(Exception):
    """Base exception for memory system"""
    pass

class VectorStoreError(MemorySystemError):
    """Vector store related errors"""
    pass

class EmbeddingError(MemorySystemError):
    """Embedding generation errors"""
    pass

# Retry decorator
import functools
import asyncio
from typing import Callable, Any

def retry_async(
    max_attempts: int = 3,
    delay: float = 1.0,
    exponential_backoff: bool = True
):
    """Async retry decorator with exponential backoff"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        wait_time = delay * (2 ** attempt) if exponential_backoff else delay
                        logger.warning(f"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"All {max_attempts} attempts failed: {e}")
            
            raise last_exception
        return wrapper
    return decorator
```

## Testing Patterns

### Async Testing with pytest
```python
import pytest
import asyncio
from httpx import AsyncClient
from unittest.mock import AsyncMock, patch

@pytest.fixture
async def async_client():
    """Async test client fixture"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        yield client

@pytest.fixture
def mock_memory_service():
    """Mock memory service for testing"""
    return AsyncMock()

@pytest.mark.asyncio
async def test_create_memory_success(async_client, mock_memory_service):
    """Test successful memory creation"""
    # Mock data
    mock_memory = Memory(
        id="test-id",
        content="test content",
        category="TEST",
        user_id="test-user"
    )
    mock_memory_service.create_memory.return_value = mock_memory
    
    # Test request
    with patch('app.memory_service', mock_memory_service):
        response = await async_client.post(
            "/api/v1/memories",
            json={
                "content": "test content",
                "category": "TEST",
                "user_id": "test-user"
            }
        )
    
    assert response.status_code == 200
    assert response.json()["content"] == "test content"

@pytest.mark.asyncio
async def test_vector_search_integration():
    """Integration test for vector search"""
    embedding_service = EmbeddingService()
    vector_store = ChromaVectorStore("test_collection")
    
    # Test embedding generation
    embedding = await embedding_service.embed_text("test query")
    assert len(embedding) > 0
    assert isinstance(embedding[0], float)
```

## Performance & Monitoring

### Async Optimization
```python
import asyncio
from contextlib import asynccontextmanager
from typing import AsyncGenerator

@asynccontextmanager
async def async_batch_processor(
    items: List[Any], 
    batch_size: int = 10
) -> AsyncGenerator[List[Any], None]:
    """Process items in async batches"""
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        yield batch
        await asyncio.sleep(0)  # Yield control

# Memory pool for embeddings
class EmbeddingPool:
    """Connection pool for embedding requests"""
    
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def embed_with_limit(self, text: str) -> List[float]:
        async with self.semaphore:
            return await self.embedding_service.embed_text(text)
```

## Configuration & Environment

### Settings Management
```python
from pydantic import BaseSettings, validator
from typing import Optional

class Settings(BaseSettings):
    """Application settings with validation"""
    
    # Database
    database_url: str
    redis_url: Optional[str] = None
    
    # AI Services
    openai_api_key: str
    embedding_model: str = "text-embedding-3-small"
    
    # Vector Store
    vector_store_type: Literal["chroma", "pinecone", "qdrant"] = "chroma"
    chroma_host: str = "localhost"
    chroma_port: int = 8000
    
    # API Configuration
    cors_origins: List[str] = ["http://localhost:3000"]
    api_key: Optional[str] = None
    
    @validator('database_url')
    def validate_database_url(cls, v):
        if not v.startswith(('postgresql://', 'sqlite://')):
            raise ValueError('Invalid database URL format')
        return v
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

settings = Settings()
```

@core-development.mdc
@memory-integration.mdc
@testing-workflows.mdc
