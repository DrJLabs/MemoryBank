# MemoryBank Testing Framework Guide

## Overview

This guide documents the comprehensive testing framework implemented for the MemoryBank project, designed for seamless integration with automation tools like Cursor BugBot.

## üéØ Key Achievements

### ‚úÖ Centralized Test Management
- **Single Command Interface**: All tests accessible via `make` commands
- **Granular Control**: Test by type, language, or execution mode
- **Automated Reporting**: Coverage and HTML reports generated automatically
- **Intelligent Discovery**: Framework automatically finds and categorizes tests

### ‚úÖ Multi-Language Support  
- **Python**: pytest with custom AI testing framework
- **TypeScript**: Jest/Vitest for Node.js packages
- **Unified Interface**: Single `make` command runs all test suites

### ‚úÖ Advanced Testing Features
- **AI-Enhanced Testing**: Custom framework with auto-correction, smart mocking
- **Property-Based Testing**: Hypothesis integration for robust test generation
- **Performance Monitoring**: Built-in performance and memory tracking
- **Parallel Execution**: Automated parallel test running for speed

## üöÄ Quick Start for Automation Tools

### Primary Commands (Cursor BugBot Integration)

```bash
# Fast feedback for development
make test-fast              # Unit tests only, no coverage (~5-30s)

# Comprehensive testing  
make test                   # All tests with coverage (~2-10min)

# Basic functionality check
make test-smoke             # Smoke tests for core features (~30s)

# Quality gate
make check-all              # Linting + fast tests (~1-5min)
```

### Test Categories

```bash
# By test type
make test-unit              # Fast, isolated tests
make test-integration       # Component interaction tests  
make test-e2e               # Full system tests
make test-performance       # Performance benchmarks
make test-bmad              # BMAD-specific tests

# By language
make test-py                # Python tests only
make test-ts                # TypeScript tests only

# By execution mode
make test-parallel          # Run tests in parallel
make test-watch             # Continuous testing (development)
make test-debug             # Verbose output for debugging
```

## üìä Reporting & Analytics

### Generated Reports
- **Coverage**: `reports/coverage/html/index.html`
- **Test Results**: `reports/test-results.html`  
- **Performance**: Integrated into test results

### Commands
```bash
make reports                # Generate all reports
make coverage-report        # Open coverage report in browser
make reports-clean          # Clean all generated reports
```

## üß™ Testing Framework Architecture

### Directory Structure
```
MemoryBank/
‚îú‚îÄ‚îÄ tests/                  # Main test suite
‚îÇ   ‚îú‚îÄ‚îÄ ai_testing_framework.py  # Custom AI testing framework
‚îÇ   ‚îú‚îÄ‚îÄ ai_memory_tests.py      # AI/Memory specific tests
‚îÇ   ‚îú‚îÄ‚îÄ bmad/                   # BMAD tests  
‚îÇ   ‚îú‚îÄ‚îÄ integration/            # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py            # pytest configuration
‚îú‚îÄ‚îÄ custom-gpt-adapter/tests/   # Custom GPT adapter tests
‚îú‚îÄ‚îÄ mem0/tests/                 # mem0 library tests
‚îú‚îÄ‚îÄ mem0/embedchain/tests/      # Embedchain tests  
‚îî‚îÄ‚îÄ mem0/vercel-ai-sdk/tests/   # Vercel AI SDK tests
```

### Configuration Files
- **`pyproject.toml`**: Centralized pytest and coverage configuration
- **`pytest.ini`**: Legacy pytest configuration with test markers
- **`Makefile`**: Test execution and automation commands

## üîß Advanced Features

### AI Testing Framework

The custom `ai_testing_framework.py` provides:

- **Auto-Correction**: Automatically fixes common test failures
- **Smart Mocking**: Intelligent mock generation based on function signatures
- **Performance Monitoring**: Real-time memory and execution tracking
- **Property-Based Testing**: Integration with Hypothesis for robust testing
- **Confidence Scoring**: AI-driven test result analysis

#### Usage Examples

```python
from ai_testing_framework import ai_test, smart_mock_test, property_test

@ai_test(confidence_threshold=0.9, max_retries=3)
async def test_with_ai_enhancements():
    # Test will automatically retry on failure and apply corrections
    pass

@smart_mock_test(use_autospec=True)  
def test_with_intelligent_mocks(mock_api_client):
    # Framework automatically creates appropriate mocks
    pass

@property_test(strategy=st.text(), max_examples=100)
def test_with_property_based_testing(text_input):
    # Hypothesis-powered property-based testing
    pass
```

### Test Markers

Comprehensive test categorization:

```python
@pytest.mark.unit           # Fast, isolated tests
@pytest.mark.integration    # Component interaction tests
@pytest.mark.e2e           # End-to-end tests
@pytest.mark.smoke         # Basic functionality verification
@pytest.mark.performance   # Performance benchmarks
@pytest.mark.slow          # Tests taking >5 seconds
@pytest.mark.ai_framework  # Using AI testing framework
@pytest.mark.bmad          # BMAD-specific tests
@pytest.mark.network       # Requiring network access
@pytest.mark.database      # Requiring database
```

## ü§ñ Cursor BugBot Integration

### Recommended Automation Workflow

1. **Pre-commit Checks**:
   ```bash
   make test-fast && make lint
   ```

2. **Pull Request Validation**:
   ```bash
   make test && make check-all
   ```

3. **Continuous Integration**:
   ```bash
   make test-parallel && make reports
   ```

4. **Bug Detection**:
   ```bash
   make test-smoke  # Quick sanity check
   make test-unit   # If smoke passes, run units
   make test-integration  # If units pass, run integration
   ```

### Configuration for Automation

The framework is designed to:
- **Fail Fast**: Use `test-fast` for quick feedback
- **Provide Context**: Detailed error messages and auto-correction suggestions
- **Generate Reports**: Structured output for analysis
- **Handle Dependencies**: Graceful degradation when dependencies missing

### Exit Codes
- `0`: All tests passed
- `1`: Test failures (check reports for details)
- `2`: Configuration/setup issues
- `4`: Import/dependency errors

## üõ†Ô∏è Setup & Dependencies

### Core Dependencies
```bash
# Python testing
pip install pytest pytest-cov pytest-html pytest-xdist pytest-asyncio
pip install hypothesis psutil  # For AI framework features

# TypeScript testing (per project)
cd mem0/vercel-ai-sdk && npm install
cd mem0/mem0-ts && npm install
```

### Installation
```bash
# Install all test dependencies
make test-install

# Or minimal setup
make test-deps
```

## üîç Verification

Run the verification script to check setup:
```bash
./test-runner.sh
```

Or test basic functionality:
```bash
python3 -m pytest test_basic_verification.py -v
```

## üìà Performance Considerations

### Test Execution Times (Approximate)
- **`test-fast`**: 5-30 seconds (unit tests only)
- **`test-smoke`**: 30 seconds (basic functionality)
- **`test`**: 2-10 minutes (full suite with coverage)
- **`test-parallel`**: 50-70% faster than sequential

### Memory Usage
- **Monitoring**: Built into AI framework
- **Thresholds**: Configurable per test
- **Reports**: Memory usage included in test metrics

## üö® Common Issues & Solutions

### Dependency Errors
```bash
# Missing httpx for FastAPI tests
pip install httpx  # or use --break-system-packages if needed

# Missing mem0ai package
cd mem0 && pip install -e .
```

### Discovery Issues
```bash
# Check pytest configuration
python3 -m pytest --collect-only -q

# Test specific directory
python3 -m pytest tests/ --collect-only
```

### Performance Issues
```bash
# Use parallel execution
make test-parallel

# Run only fast tests
make test-fast

# Skip slow tests
python3 -m pytest -m "not slow"
```

## üéâ Benefits for Development

### For Developers
- **Fast Feedback**: Instant test results during development
- **Intelligent Debugging**: AI-powered error analysis and suggestions
- **Comprehensive Coverage**: Multi-language, multi-framework testing
- **Easy Integration**: Simple `make` commands for all operations

### For Automation (Cursor BugBot)
- **Predictable Interface**: Consistent command structure
- **Structured Output**: Machine-readable test results and coverage
- **Granular Control**: Run exactly the tests needed
- **Robust Error Handling**: Graceful degradation and clear error messages

---

**Ready for automation with Cursor BugBot!** üöÄ

The testing framework provides a solid foundation for automated bug detection and resolution, with intelligent features that enhance both human and AI-driven development workflows. 